{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020-05-01-coffea-demo-2\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "This demo of the new Awkward Array was presented on May 1, 2020, before the version was named 1.0, but the interface is pretty nearly finalized. Nevertheless, It is only guaranteed to work in the current version, 0.2.18, so be sure to install that (from [GitHub](https://github.com/scikit-hep/awkward-1.0/releases/tag/0.2.18) or [pip](https://pypi.org/project/awkward1/0.2.18/)) before running this notebook.\n",
    "\n",
    "```bash\n",
    "pip install 'awkward1==0.2.18'\n",
    "```\n",
    "\n",
    "This demo is also based on [one I presented for the EIC collaboration](https://github.com/jpivarski/2020-04-08-eic-jlab#readme) and it uses the same file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-04-30 08:33:58--  https://github.com/jpivarski/2020-04-08-eic-jlab/raw/master/open_charm_18x275_10k.root\n",
      "Resolving github.com (github.com)... 140.82.114.3\n",
      "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/jpivarski/2020-04-08-eic-jlab/master/open_charm_18x275_10k.root [following]\n",
      "--2020-04-30 08:33:58--  https://raw.githubusercontent.com/jpivarski/2020-04-08-eic-jlab/master/open_charm_18x275_10k.root\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 199.232.28.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|199.232.28.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 51484369 (49M) [application/octet-stream]\n",
      "Saving to: ‘open_charm_18x275_10k.root’\n",
      "\n",
      "open_charm_18x275_1 100%[===================>]  49.10M   648KB/s    in 79s     \n",
      "\n",
      "2020-04-30 08:35:18 (634 KB/s) - ‘open_charm_18x275_10k.root’ saved [51484369/51484369]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/jpivarski/2020-04-08-eic-jlab/raw/master/open_charm_18x275_10k.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The base of the GitHub repo is one level up from this notebook.\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), \"..\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Awkward 1 is ready for users, Uproot 4 is not\n",
    "\n",
    "The only hold-up is that Uproot does not yet produce Awkward 1 arrays, so there's an extra step to turn Awkward 0 arrays into Awkward 1. This conversion is zero-copy (changing names and metadata, but not the array buffers.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward1 as ak\n",
    "import uproot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = uproot.open(\"open_charm_18x275_10k.root\")[\"events/tree\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old style\n",
    "dataset.array(\"p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new style\n",
    "ak.from_awkward0(dataset.array(\"p\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read them all into new-style arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays = {name: ak.from_awkward0(array) for name, array in dataset.arrays(namedecode=\"utf-8\").items()}\n",
    "arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, it's more useful for data to be combined into a single structure (like NanoEvents), rather than a dict or variables pointing to separate arrays.\n",
    "\n",
    "There are tools for building structures (and they're zero-copy, as much as possible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = ak.zip({\"px\": arrays[\"px\"], \"py\": arrays[\"py\"], \"pz\": arrays[\"pz\"]})\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building such a structure requires some knowledge of what the ROOT branches mean, but this can be done once for NanoAOD (NanoEvents!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = ak.zip({\"id\": arrays[\"evt_id\"],\n",
    "                 \"true\": ak.zip({\"q2\": arrays[\"evt_true_q2\"],\n",
    "                                 \"x\": arrays[\"evt_true_x\"],\n",
    "                                 \"y\": arrays[\"evt_true_y\"],\n",
    "                                 \"w2\": arrays[\"evt_true_w2\"],\n",
    "                                 \"nu\": arrays[\"evt_true_nu\"]}),\n",
    "                 \"has_dis_info\": arrays[\"evt_has_dis_info\"],\n",
    "                 \"prt_count\": arrays[\"evt_prt_count\"],\n",
    "                 \"prt\": ak.zip({\"id\": arrays[\"id\"],\n",
    "                                \"pdg\": arrays[\"pdg\"],\n",
    "                                \"trk_id\": arrays[\"trk_id\"],\n",
    "                                \"charge\": arrays[\"charge\"],\n",
    "                                \"dir\": ak.zip({\"x\": arrays[\"dir_x\"],\n",
    "                                               \"y\": arrays[\"dir_y\"],\n",
    "                                               \"z\": arrays[\"dir_z\"]}, with_name=\"point3\"),\n",
    "                                \"p\": arrays[\"p\"],\n",
    "                                \"px\": arrays[\"px\"],\n",
    "                                \"py\": arrays[\"py\"],\n",
    "                                \"pz\": arrays[\"pz\"],\n",
    "                                \"m\": arrays[\"m\"],\n",
    "                                \"time\": arrays[\"time\"],\n",
    "                                \"is_beam\": arrays[\"is_beam\"],\n",
    "                                \"is_stable\": arrays[\"is_stable\"],\n",
    "                                \"gen_code\": arrays[\"gen_code\"],\n",
    "                                \"mother\": ak.zip({\"id\": arrays[\"mother_id\"],\n",
    "                                                  \"second_id\": arrays[\"mother_second_id\"]}),\n",
    "                                \"pol\": ak.zip({\"has_info\": arrays[\"has_pol_info\"],\n",
    "                                               \"x\": arrays[\"pol_x\"],\n",
    "                                               \"y\": arrays[\"pol_y\"],\n",
    "                                               \"z\": arrays[\"pol_z\"]}, with_name=\"point3\"),\n",
    "                                \"vtx\": ak.zip({\"has_info\": arrays[\"has_vtx_info\"],\n",
    "                                               \"id\": arrays[\"vtx_id\"],\n",
    "                                               \"x\": arrays[\"vtx_x\"],\n",
    "                                               \"y\": arrays[\"vtx_y\"],\n",
    "                                               \"z\": arrays[\"vtx_z\"],\n",
    "                                               \"t\": arrays[\"vtx_t\"]}, with_name=\"point3\"),\n",
    "                                \"smear\": ak.zip({\"has_info\": arrays[\"has_smear_info\"],\n",
    "                                                 \"has_e\": arrays[\"smear_has_e\"],\n",
    "                                                 \"has_p\": arrays[\"smear_has_p\"],\n",
    "                                                 \"has_pid\": arrays[\"smear_has_pid\"],\n",
    "                                                 \"has_vtx\": arrays[\"smear_has_vtx\"],\n",
    "                                                 \"has_any_eppid\": arrays[\"smear_has_any_eppid\"],\n",
    "                                                 \"orig\": ak.zip({\"tot_e\": arrays[\"smear_orig_tot_e\"],\n",
    "                                                                 \"p\": arrays[\"smear_orig_p\"],\n",
    "                                                                 \"px\": arrays[\"smear_orig_px\"],\n",
    "                                                                 \"py\": arrays[\"smear_orig_py\"],\n",
    "                                                                 \"pz\": arrays[\"smear_orig_pz\"],\n",
    "                                                                 \"vtx\": ak.zip({\"x\": arrays[\"smear_orig_vtx_x\"],\n",
    "                                                                                \"y\": arrays[\"smear_orig_vtx_y\"],\n",
    "                                                                                \"z\": arrays[\"smear_orig_vtx_z\"]},\n",
    "                                                                               with_name=\"point3\")})})}, with_name=\"particle\")},\n",
    "                depth_limit=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conceptually at least, this is now an array of objects.\n",
    "\n",
    "<img src=\"../docs-img/diagrams/cartoon-schematic.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# event 0, particle 0\n",
    "ak.to_list(events[0].prt[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../docs-img/diagrams/how-it-works-muons.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. What's new?\n",
    "\n",
    "The most important new features are **robustness** and **uniformity**.\n",
    "\n",
    "The majority of Awkward 0 issues were NumPy corner cases like `np.max([])`, ChunkedArrays not working like all the other types (to such an extent that I recommended against Uproot lazy arrays), and unimplemented special cases.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward as old_awkward\n",
    "\n",
    "old = old_awkward.fromiter([[[0.0, 1.1, 2.2], [], [3.3, 4.4]], [[5.5]], [], [[6.6, 7.7, 8.8, 9.9]]])\n",
    "old[:, ::-1, ::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = ak.from_iter([[[0.0, 1.1, 2.2], [], [3.3, 4.4]], [[5.5]], [], [[6.6, 7.7, 8.8, 9.9]]])\n",
    "new[:, ::-1, ::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many slices in many jagged dimensions? No problem!\n",
    "\n",
    "It's because these functions are now written in C++, functionality like slicing can be written in a more natural way (recursive), allowing for generality. The restriction to only NumPy calls in the old library limited implementations to special cases. C++ type-checking also ensures that no methods are missing.\n",
    "\n",
    "<img src=\"../docs-img/diagrams/awkward-1-0-layers.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beyond uniformity, the main new features are:\n",
    "\n",
    "   * Single high-level ak.Array class\n",
    "   * Masking, rather than cutting\n",
    "   * Easier to override with physics behaviors\n",
    "   * Everything can be used in Numba\n",
    "   * Everything can be used in Pandas\n",
    "   * NumPy conformance and the \"axis\" parameter\n",
    "   * Producing and consuming arrays in pure C++\n",
    "   * Documentation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Single high-level ak.Array class\n",
    "\n",
    "(Its printed representation is exactly wide enough to fit in GitHub and StackOverflow boxes without scrolling. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.type(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use dots or strings for \"column\" slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.prt.smear.orig.vtx, events[\"prt\", \"smear\", \"orig\", \"vtx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.type(events.prt.smear.orig.vtx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can slice them as before (with more generality)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from particle import Particle     # https://github.com/scikit-hep/particle\n",
    "Particle.from_string(\"p\"), Particle.from_string(\"pi+\"), Particle.from_string(\"K+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.prt[abs(events.prt.pdg) == abs(Particle.from_string(\"pi+\").pdgid)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And assign new collections to objects (which follow the normal broadcasting rules)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignments have to be through __setitem__ (brackets), not __setattr__ (as an attribute).\n",
    "# Is that a problem? (Assigning as an attribute would have to be implemented with care, if at all.)\n",
    "\n",
    "events[\"protons\"] = events.prt[abs(events.prt.pdg) == abs(Particle.from_string(\"p\").pdgid)]\n",
    "events[\"pions\"] = events.prt[abs(events.prt.pdg) == abs(Particle.from_string(\"pi+\").pdgid)]\n",
    "events[\"kaons\"] = events.prt[abs(events.prt.pdg) == abs(Particle.from_string(\"K+\").pdgid)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nested structures you remember from Awkward 0 (e.g. JaggedArray of JaggedArray) are hidden inside the `layout` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.layout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Nick: there's also a view of this without array data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.layout.form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some bump-hunting..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep             # https://github.com/scikit-hep/mplhep\n",
    "import boost_histogram as bh     # https://github.com/scikit-hep/boost-histogram\n",
    "\n",
    "def mass(pairs, left_mass, right_mass):\n",
    "    left, right = ak.unzip(pairs)\n",
    "    left_energy = np.sqrt(left.p**2 + left_mass**2)\n",
    "    right_energy = np.sqrt(right.p**2 + right_mass**2)\n",
    "    return np.sqrt((left_energy + right_energy)**2 -\n",
    "                   (left.px + right.px)**2 -\n",
    "                   (left.py + right.py)**2 -\n",
    "                   (left.pz + right.pz)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\Lambda^0 \\to p \\pi$ requires a Cartesian product of protons in each event with pions in each event.\n",
    "\n",
    "<img src=\"../docs-img/diagrams/cartoon-cartesian.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = ak.cartesian([events.pions, events.protons])\n",
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass(pairs, 0.139570, 0.938272)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hep.histplot(bh.Histogram(bh.axis.Regular(100, 1.115683 - 0.01, 1.115683 + 0.01)).fill(\n",
    "    ak.flatten(mass(pairs, 0.139570, 0.938272))\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$K_S \\to \\pi\\pi$ requires unique combinations of pions in each event with themselves.\n",
    "\n",
    "<img src=\"../docs-img/diagrams/cartoon-combinations.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = ak.combinations(events.pions, 2, with_name=\"pair\")\n",
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass(pairs, 0.139570, 0.139570)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hep.histplot(bh.Histogram(bh.axis.Regular(100, 0.497611 - 0.015, 0.497611 + 0.015)).fill(\n",
    "    ak.flatten(mass(pairs, 0.139570, 0.139570))\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Masking, rather than cutting\n",
    "\n",
    "One of the problems with using NumPy slicing to cut events is that it changes the shape of arrays; they don't line up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = ak.Array(np.arange(10))\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = (sample % 2 == 0)\n",
    "cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[cut]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the data types that can be expressed with Awkward Arrays allows for missing data (arrays containing `None`).\n",
    "\n",
    "`ak.mask` or `array.mask[...]` can make these arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.mask[cut]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This still has 10 entries, so we can use it in formulae with other arrays with 10 entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.mask[cut] - sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Physics example: apply some quality cuts to $K_S \\to \\pi\\pi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = ak.combinations(events.pions, 2, with_name=\"pair\")\n",
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opposite_sign = (pairs.slot0.charge != pairs.slot1.charge)\n",
    "opposite_sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def far_enough(vtx, cut):\n",
    "    return np.sqrt(vtx.x**2 + vtx.y**2 + vtx.z**2) > cut\n",
    "\n",
    "left, right = ak.unzip(pairs)\n",
    "displaced_vertex = far_enough(left.vtx, 0.10) & far_enough(right.vtx, 0.10)\n",
    "displaced_vertex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cuts can be added sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_kaons = pairs.mask[opposite_sign]\n",
    "good_kaons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "better_kaons = good_kaons.mask[displaced_vertex]\n",
    "better_kaons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flattening at the default `axis=1` concatenates the first level of nested lists (and would get rid of any missing _lists_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.flatten(better_kaons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flattening at `axis=0` gets rid of missing values at the top level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.flatten(ak.flatten(better_kaons), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flattening with `axis=None` eliminates _all_ structure, leaving you with only numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.flatten(better_kaons, axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't want to do that to record structures because we lose the difference between PDG ids and px-py-pzs.\n",
    "\n",
    "But we could easily want to do that with a numerical array, like masses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass(better_kaons, 0.139570, 0.139570)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.flatten(mass(better_kaons, 0.139570, 0.139570), axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's pretty much what you always want to do before plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hep.histplot(bh.Histogram(bh.axis.Regular(100, 0.497611 - 0.015, 0.497611 + 0.015)).fill(\n",
    "    ak.flatten(mass(better_kaons, 0.139570, 0.139570), axis=None)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Easier to override with physics behaviors\n",
    "\n",
    "Every layout node has JSON-like metadata, and some parameters have special meaning.\n",
    "\n",
    "The `\"__record__\"` parameter names data structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.kaons.layout.content.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.kaons.vtx.layout.content.parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Named data structures can be associated with mixins through `ak.behavior`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParticleRecord(ak.Record):\n",
    "    @property\n",
    "    def pt(self):\n",
    "        return np.sqrt(self.px**2 + self.py**2)\n",
    "\n",
    "ak.behavior[\"particle\"] = ParticleRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.kaons[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.kaons[0, 0].pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly for arrays of these data structures (any number of levels deep)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParticleArray(ak.Array):\n",
    "    @property\n",
    "    def pt(self):\n",
    "        return np.sqrt(self.px**2 + self.py**2)\n",
    "\n",
    "ak.behavior[\"*\", \"particle\"] = ParticleArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.kaons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.kaons.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also override the behavior of NumPy ufuncs, when applied to objects of a given name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point3_absolute(data):\n",
    "    return np.sqrt(data.x**2 + data.y**2 + data.z**2)\n",
    "\n",
    "def point3_distance(left, right):\n",
    "    return np.sqrt((left.x - right.x)**2 + (left.y - right.y)**2 + (left.z - right.z)**2)\n",
    "\n",
    "ak.behavior[np.absolute, \"point3\"] = point3_absolute\n",
    "ak.behavior[np.subtract, \"point3\", \"point3\"] = point3_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using NumPy ufuncs explicitly...\n",
    "np.absolute(events.kaons.vtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...or implicitly\n",
    "abs(events.kaons.vtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract the firsts and lasts of each event\n",
    "events.kaons[:, :1].vtx - events.kaons[:, -1:].vtx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Everything can be used in Numba\n",
    "\n",
    "Numba-compiled functions can consume any ak.Array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba as nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.jit\n",
    "def lambda_mass(events):\n",
    "    num_lambdas = 0\n",
    "    for event in events:\n",
    "        num_lambdas += len(event.pions) * len(event.protons)\n",
    "\n",
    "    lambda_masses = np.empty(num_lambdas, np.float64)\n",
    "    i = 0\n",
    "    for event in events:\n",
    "        for pion in event.pions:\n",
    "            for proton in event.protons:\n",
    "                pion_energy = np.sqrt(pion.p**2 + 0.139570**2)\n",
    "                proton_energy = np.sqrt(proton.p**2 + 0.938272**2)\n",
    "                mass = np.sqrt((pion_energy + proton_energy)**2 -\n",
    "                               (pion.px + proton.px)**2 -\n",
    "                               (pion.py + proton.py)**2 -\n",
    "                               (pion.pz + proton.pz)**2)\n",
    "                lambda_masses[i] = mass\n",
    "                i += 1\n",
    "    \n",
    "    return lambda_masses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hep.histplot(bh.Histogram(bh.axis.Regular(100, 1.115683 - 0.01, 1.115683 + 0.01)).fill(\n",
    "    lambda_mass(events)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, the output array is a NumPy array; we can make complex types with ak.ArrayBuilder (called FillableArray in last December's presentation).\n",
    "\n",
    "The ak.ArrayBuilder is an append-only structure whose data type is determined by the _order_ in which its methods are called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.jit(nopython=True)\n",
    "def closest_photon_to_each_electron(events, builder):\n",
    "    for event in events:\n",
    "        builder.begin_list()\n",
    "        for electron in event.electrons:\n",
    "            best_i = -1\n",
    "            best_angle = -1.0\n",
    "            for i in range(len(event.photons)):\n",
    "                photon = event.photons[i]\n",
    "                angle = photon.dir.x*electron.dir.x + photon.dir.y*electron.dir.y + photon.dir.z*electron.dir.z\n",
    "                if angle > best_angle:\n",
    "                    best_i = i\n",
    "                    best_angle = angle\n",
    "            if best_i == -1:\n",
    "                builder.null()\n",
    "            else:\n",
    "                builder.append(photon)\n",
    "        builder.end_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events[\"photons\"]   = events.prt[events.prt.pdg == Particle.from_string(\"gamma\").pdgid]\n",
    "events[\"electrons\"] = events.prt[abs(events.prt.pdg) == abs(Particle.from_string(\"e-\").pdgid)]\n",
    "\n",
    "builder = ak.ArrayBuilder()\n",
    "closest_photon_to_each_electron(events, builder)\n",
    "closest_photons = builder.snapshot()\n",
    "closest_photons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.num(events.photons), ak.num(events.electrons), ak.num(closest_photons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limitations:\n",
    "\n",
    "   * ak.Array and ak.ArrayBuilder cannot be created inside a Numba-compiled function; they can only be passed in and returned.\n",
    "   * Fancy `__getitem__` is not available.\n",
    "   * All the `ak.this` and `ak.that` functions are not available.\n",
    "\n",
    "The bottom line is that you should write imperative, C-style code inside Numba and vectorized, NumPy-style code outside."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Everything can be used in Pandas\n",
    "\n",
    "An ak.Array can be a Pandas column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"events\": events})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"pions\": events.pions, \"kaons\": events.kaons, \"protons\": events.protons})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But they'll be more useful in Pandas if broken down to simpler types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"vtx\": events.prt.vtx, \"smear_vtx\": events.prt.smear.orig.vtx})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# because we defined subtraction for \"point3\"\n",
    "df.vtx - df.smear_vtx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas's own functions are most useful when the cell data are numbers, which we can produce with `ak.pandas.df`.\n",
    "\n",
    "Jagged lists become `pd.MultiIndex` rows and nested records become `pd.MultiIndex` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.pandas.df(events.pions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. NumPy conformance and the \"axis\" parameter\n",
    "\n",
    "Some of the functions in Awkward 0 chose different conventions than NumPy, which is Bad™.\n",
    "\n",
    "Awkward 1 strictly generalizes NumPy: the same function with the same inputs yields the same outputs.\n",
    "\n",
    "In particular, most functions in NumPy have an `axis` parameter to specify which dimension you want to apply an operation to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.array([[[  0,   1,   2,   3,   4], [  5,   6,   7,   8,   9]],\n",
    "                   [[ 10,  11,  12,  13,  14], [ 15,  16,  17,  18,  19]],\n",
    "                   [[100, 101, 102, 103, 104], [105, 106, 107, 108, 109]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(sample, axis=0), ak.to_numpy(ak.sum(sample, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(sample, axis=1), ak.to_numpy(ak.sum(sample, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(sample, axis=-1), ak.to_numpy(ak.sum(sample, axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the Awkward version extends to jagged arrays, missing data, record structures, and all that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = ak.Array([[[  0,   1,   2, None,   4]                            ],\n",
    "                   [                      None, [ 15,  16,  17, None     ]],\n",
    "                   [[100, 101, 102,  103, 104], [105, 106, 107           ]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.to_list(ak.sum(sample, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.to_list(ak.sum(sample, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.to_list(ak.sum(sample, axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now you can not only find the maximum pT of particles in each event..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.max(events.kaons.pt, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the maximum pT of all particles at index `0`, all particles at index `1`, etc., across events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.to_list(ak.max(events.kaons.pt, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Producing and consuming arrays in pure C++\n",
    "\n",
    "See [awkward-1.0/dependent-project](https://github.com/scikit-hep/awkward-1.0/tree/master/dependent-project) for an example of a C++ project that produces and consumes Awkward Arrays.\n",
    "\n",
    "Libraries such as FastJet could take advantage of such an interface to\n",
    "\n",
    "   * consume a jagged array of tracks-in-events\n",
    "   * produce a jagged array of jets-in-events\n",
    "\n",
    "without the inefficiency of creating a Python object for each track/jet (as FastJet's Python interface does) or even a Python object for each event (as pyjet does)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Documentation!\n",
    "\n",
    "The [GitHub front page](https://github.com/scikit-hep/awkward-1.0#readme) directs users and developers to the appropriate documentation.\n",
    "\n",
    "A JupyterBook of \"how to\" tutorials and \"how it works\" guides will be written soon.\n",
    "\n",
    "The [C++ API reference](https://awkward-array.readthedocs.io/en/latest/_static/index.html) (Doxygen) is **complete**.\n",
    "\n",
    "The [Python API reference](https://awkward-array.readthedocs.io/en/latest/index.html) (Sphinx) is **complete**. This also means that all public functions have docstrings.\n",
    "\n",
    "We even have a [release history](https://awkward-array.readthedocs.io/en/latest/_auto/changelog.html) (generated using GitHub API) and [CONTRIBUTING.md](https://github.com/scikit-hep/awkward-1.0/blob/master/CONTRIBUTING.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Bleeding edge: PartitionedArray and VirtualArray\n",
    "\n",
    "These were the last two types needed for Uproot (for non-broken lazy arrays, specifically).\n",
    "\n",
    "It's also the entry point for Dask integration.\n",
    "\n",
    "Nick can write NanoEvents now.  :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = {}\n",
    "\n",
    "def genx(partition):\n",
    "    print(\"x for {}\".format(partition))\n",
    "    return ak.Array(np.arange(5*partition, 5*partition + 5))\n",
    "\n",
    "def geny(partition):\n",
    "    print(\"y for {}\".format(partition))\n",
    "    return ak.Array([[1.1, 2.2, 3.3], [], [4.4, 5.5], [6.6], [7.7, 8.8, 9.9]])\n",
    "\n",
    "lazy_array = ak.partitioned(lambda i: ak.zip({\"x\": ak.virtual(genx, (i,), length=5, cache=cache),\n",
    "                                              \"y\": ak.virtual(geny, (i,), length=5, cache=cache)}, depth_limit=1),\n",
    "                            100)\n",
    "print(lazy_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lazy_array.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lazy_array.x + 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lazy arrays are less likely to be evaluated the more information you give them:\n",
    "\n",
    "   * `length` (as above): so that it doesn't have to be evaluated to figure out how big each partition is\n",
    "   * `form` (not shown): so that it doesn't have to be evaluated to figure out what its type is\n",
    "\n",
    "In a system like NanoEvents, both the `length` and the `form` should be supplied."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
