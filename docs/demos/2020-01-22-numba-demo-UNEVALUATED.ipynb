{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020-01-22-numba-demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. This notebook\n",
    "\n",
    "This demo of Awkward Array was presented on January 22, 2020, before the first stable version (1.0) was released. Some interfaces may have changed. To run this notebook, make sure you have version 0.1.87  ([GitHub](https://github.com/scikit-hep/awkward-1.0/releases/tag/0.1.87), [pip](https://pypi.org/project/awkward1/0.1.87/)) by installing\n",
    "\n",
    "```bash\n",
    "pip install 'awkward1==0.1.87'\n",
    "```\n",
    "\n",
    "before executing it in Jupyter (or include that release number in the Binder URL).\n",
    "\n",
    "Depending on where you execute this notebook and how you installed or didn't install Awkward Array, you might need the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The base of the GitHub repo is two levels up from this notebook.\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), \"..\", \"..\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Introduction to Awkward Array\n",
    "\n",
    "Awkward Array is a library for manipulating data structures with NumPy-like idioms. For a core set of NumPy features—slicing, broadcasting, array-at-a-time operations, and such—it is a strict generalization from rectilinear arrays of numeric data types to unequal-width and heterogeneous lists and nested objects.\n",
    "\n",
    "The name arose organically: these kinds of arrays are usually awkward to deal with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Distinction from NumPy object arrays\n",
    "\n",
    "Although NumPy arrays can contain arbitrary objects with `dtype('O')` type, those arrays can't be sliced or operated on with NumPy's usual idioms because they're really just pointers to pure Python objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import awkward1 as ak\n",
    "\n",
    "nparray = np.array([[1, 2, 3], [], [4, None, 5], [{\"something\": 1, \"else\": [2, 3]}]])\n",
    "akarray = ak.Array([[1, 2, 3], [], [4, None, 5], [{\"something\": 1, \"else\": [2, 3]}]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy can't slice into the substructure of Python objects.\n",
    "nparray[2:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But Awkward Array can.\n",
    "akarray[2:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy can't pass ufuncs into parts of Python objects.\n",
    "np.sin(nparray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But Awkward Array can.\n",
    "np.sin(akarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's a little more detail on the above:\n",
    "ak.tolist(np.sin(akarray))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Columnar structure\n",
    "\n",
    "Like NumPy (as well as [Apache Arrow](https://arrow.apache.org/) and [XND](https://xnd.io/)), Awkward Array operates on columnar arrays and prefers _O(1)_ views, rather than _O(n)_ computations (where _n_ is the number of elements in the array) wherever possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columnar structure of the above array:\n",
    "akarray.layout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We started printing layout object representations in Pythonic `<angle brackets>` until we had to start nesting them, then XML seemed like an obvious generalization.\n",
    "\n",
    "High-level data types are expressed in [Datashape](https://datashape.readthedocs.io/en/latest/) notation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.typeof(akarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with [extensions where necessary](https://github.com/blaze/datashape/issues/237). Similarly, these arrays will be portable to and from Apache Arrow (and other formats, if requested).\n",
    "\n",
    "The idea is that Awkward Array provides **manipulation** capabilities, not **serialization** or **transport**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Relevance for Numba\n",
    "\n",
    "Numba, as you know, provides **computation** capabilities in a way that complements NumPy. Whereas NumPy requires array-at-a-time operations for performance, Numba enables imperative, pure Python code to have equal and often exceeding performance.\n",
    "\n",
    "The analogy with Awkward is one-to-one:\n",
    "\n",
    "|   | without Numba | with Numba |\n",
    "|:-:|:-------------:|:----------:|\n",
    "| **with NumPy** | array-at-a-time processing on numbers | general code on NumPy arrays and Python objects |\n",
    "| **with Awkward** | array-at-a-time processing on data structures | general code on Awkward data structures |\n",
    "\n",
    "The Awkward Array library includes Numba extensions with near feature parity: most operations that run outside of JIT-compiled functions run inside them as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba as nb\n",
    "\n",
    "@nb.jit(nopython=True)\n",
    "def run(array):\n",
    "    out = np.empty(len(array), np.float64)\n",
    "    for i in range(len(array)):\n",
    "        out[i] = array[i][\"x\"]\n",
    "        for y in array[i][\"y\"]:\n",
    "            out[i] += y\n",
    "    return out\n",
    "\n",
    "akarray = ak.Array([{\"x\": 100, \"y\": [1.1, 2.2]}, {\"x\": 200, \"y\": []}, {\"x\": 300, \"y\": [3.3]}])\n",
    "\n",
    "# Works for the layout nodes, but not the high-level ak.Array wrapper yet.\n",
    "run(akarray.layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although Numba can take and return builtin Python objects (e.g. tuples, lists, dicts) and can let you define extensions for class instances with `@jitclass`, these objects need to be unboxed and boxed to Python types, which can be a bottleneck for large datasets. (At the very least, Python objects are a memory bottleneck!)\n",
    "\n",
    "Since data in an Awkward Array are columnar, boxing and unboxing scales with the depth of the columnar layout, not the number of elements in the array. In this example, 4 array nodes were unboxed, though the array could have a million elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "akarray.layout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/example-hierarchy.png\" style=\"width: 800px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate, let's make an array with the same type and a million elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "\n",
    "builder = ak.FillableArray()\n",
    "\n",
    "for i in range(1000000):\n",
    "    builder.beginrecord()\n",
    "    builder.field(\"x\")\n",
    "    builder.integer(np.random.poisson(3) * 100)\n",
    "    builder.field(\"y\")\n",
    "    builder.beginlist()\n",
    "    for j in range(np.random.poisson(3)):\n",
    "        builder.real(np.random.randint(5) * 1.1)\n",
    "    builder.endlist()\n",
    "    builder.endrecord()\n",
    "\n",
    "akarray = builder.snapshot()\n",
    "print(akarray, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(akarray.layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even use Numba to build data structures with `FillableArray`, with a dramatic speedup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "\n",
    "@nb.jit(nopython=True)\n",
    "def build(builder):\n",
    "    for i in range(1000000):\n",
    "        builder.beginrecord()\n",
    "        builder.field(\"x\")\n",
    "        builder.integer(np.random.poisson(3) * 100)\n",
    "        builder.field(\"y\")\n",
    "        builder.beginlist()\n",
    "        for j in range(np.random.poisson(3)):\n",
    "            builder.real(np.random.randint(5) * 1.1)\n",
    "        builder.endlist()\n",
    "        builder.endrecord()\n",
    "    return builder\n",
    "\n",
    "print(ak.Array(build(ak.layout.FillableArray()).snapshot()), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The equivalent in Numba is about as fast, though it has to box _O(million)_ lists and numbers (and we're building `outx` and `outy` separately)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "\n",
    "@nb.jit(nopython=True)\n",
    "def build():\n",
    "    outx = []\n",
    "    outy = []\n",
    "    for i in range(1000000):\n",
    "        outx.append(np.random.poisson(3) * 100)\n",
    "        tmp = []\n",
    "        for j in range(np.random.poisson(3)):\n",
    "            tmp.append(np.random.randint(5) * 1.1)\n",
    "        outy.append(tmp)\n",
    "    return (outx, outy)\n",
    "\n",
    "outx, outy = build()\n",
    "print(outx[:5])\n",
    "print(outy[:5], end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Why particle physics?\n",
    "\n",
    "In our field, big datasets and nested data structures are ubiquitous. Nearly every physics analysis has to associate undiffentiated final-state particle trajectories to a hypothetical, hierarchical decay chain, such as this one:\n",
    "\n",
    "<img src=\"img/ttbarHDecayDiagram_expanded.png\" style=\"width: 800px;\">\n",
    "\n",
    "for billions of collision events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the match has been made, the labeled particles could be represented by a rectilinear table. However, the task of looping through candidate combinations and uncertainties associated with pruning candidates _is the whole analysis, not a preprocessing step_. For most of the analysis, we are working with unequal-sized collections of objects (momentum vector components, energy, and other variables derived from detector measurements)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our field has always had this problem. Even before Fortran had objects (or a multi-line `IF` statement!), specialized physics software added the ability to operate on data structures. This is an exerpt from [Initiation to Hydra (1974)](https://cds.cern.ch/record/864527) by R.K. Böck, describing the concept of a non-numerical data structure to a physics audience.\n",
    "\n",
    "<img src=\"img/hydra-2.png\" style=\"width: 500px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the 1990's, object-oriented programming in C++ has been good for our field: it's natural to think of each particle as a C++ object with statically typed attributes, collected in variable-length `std::vector<Particle>`s.\n",
    "\n",
    "**However,**\n",
    "\n",
    "   * **we want to use Python:** last year marked a crossover threshold in which more physicist's GitHub repositories were [written in Python than C++](img/github-fraction.png),\n",
    "   * **we still have huge datasets:** 10's of TB after considerable reduction (from the original 100's of PB)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy would be good for our analysis scripts if it had more data types than rectilinear arrays of numbers. Pandas's [MultiIndex](https://pandas.pydata.org/pandas-docs/stable/user_guide/advanced.html) is good for a single ragged dimension, but doesn't come close to what we need overall. Numba is excellent, but we need to get large datasets in and out efficiently. (Our [file format is already columnar](https://github.com/scikit-hep/uproot#readme); making intermediate Python objects would be a waste.)\n",
    "\n",
    "Awkward Array was introduced to particle physicists in September 2019 and [is very popular in our community](../img/awkward-0-popularity.png). Emboldened by this response, I'm reimplementing it in a way that will make Numba, C++, and GPU integration easier to maintain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Why not particle physics?\n",
    "\n",
    "There's nothing domain-specific about nested data structures. The kinds of operations we want to do are [logical extensions of NumPy](https://github.com/jpivarski/2019-07-29-dpf-python/blob/master/03-columnar-data-analysis.ipynb) and can also be expressed as [per-array-item SQL](https://github.com/lgray/AwkwardQL#readme). Also wanting a general programming environment in Numba also has nothing, specifically, to do with particle physics.\n",
    "\n",
    "There must be many other applications. How about this one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-01-21 16:24:22--  https://datahub.io/core/geo-countries/r/countries.geojson\n",
      "Resolving datahub.io (datahub.io)... 104.24.113.103, 104.24.112.103, 2606:4700:3035::6818:7167, ...\n",
      "Connecting to datahub.io (datahub.io)|104.24.113.103|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://pkgstore.datahub.io/core/geo-countries/countries/archive/23f420f929e0e09c39d916b8aaa166fb/countries.geojson [following]\n",
      "--2020-01-21 16:24:24--  https://pkgstore.datahub.io/core/geo-countries/countries/archive/23f420f929e0e09c39d916b8aaa166fb/countries.geojson\n",
      "Resolving pkgstore.datahub.io (pkgstore.datahub.io)... 104.24.113.103, 104.24.112.103, 2606:4700:3036::6818:7067, ...\n",
      "Connecting to pkgstore.datahub.io (pkgstore.datahub.io)|104.24.113.103|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 24090863 (23M) [application/octet-stream]\n",
      "Saving to: ‘countries.geojson’\n",
      "\n",
      "countries.geojson   100%[===================>]  22.97M  3.01MB/s    in 13s     \n",
      "\n",
      "2020-01-21 16:24:38 (1.76 MB/s) - ‘countries.geojson’ saved [24090863/24090863]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://datahub.io/core/geo-countries/r/countries.geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = ak.Array(\"countries.geojson\")\n",
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.typeof(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# longitude coordinates\n",
    "countries[\"features\", \"geometry\", \"coordinates\", :, :, :, :, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latitude coordinates\n",
    "countries[\"features\", \"geometry\", \"coordinates\", :, :, :, :, :, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fact that data analysts have managed so far with table-oriented tools like Pandas and SQL doesn't mean that they couldn't do more if they had irregular data structures, too. Being able to write arbitrary algorithms in Numba on these big, irregular data structures further extends that reach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Awkward Array implementations\n",
    "\n",
    "### 3.1 Motivation for Awkward 1.0\n",
    "\n",
    "The \"0.x\" version of Awkward (the one that is currently in use) is implemented entirely in NumPy. For performance, all of its algorithms must be expressed in a sequence of array-at-a-time calls, which led to [extremely clever case-by-case solutions](https://github.com/scikit-hep/awkward-array/blob/3442c51ed5dafb7d94f828c6cdc07659f9c03244/awkward/array/jagged.py#L1120-L1213).\n",
    "\n",
    "In the end, though, we just can't generalize without being able to write `for` loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward as oldak\n",
    "\n",
    "oldarray = oldak.fromiter([[[0.0, 1.1, 2.2], [], [3.3, 4.4]], [[5.5]], [], [[6.6, 7.7, 8.8, 9.9]]])\n",
    "newarray =       ak.Array([[[0.0, 1.1, 2.2], [], [3.3, 4.4]], [[5.5]], [], [[6.6, 7.7, 8.8, 9.9]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldarray[:, ::-1, ::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.tolist(newarray[:, ::-1, ::2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original library had [awkward-numba](https://github.com/scikit-hep/awkward-array/tree/master/awkward-numba) and [awkward-cpp](https://github.com/scikit-hep/awkward-array/tree/master/awkward-cpp) subprojects, with the intention of adding an \"awkward-gpu\", but the difficulty of maintaining them as independent implementations (which must return identical results!) would have been too much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Layered architecture\n",
    "\n",
    "Awkward 1.0 is structured in four layers:\n",
    "\n",
    "   1. The `ak.Array` class and `ak.*` operations used directly by data analysts.\n",
    "   2. The node objects that compose to form columnar data structures (in Python via pybind11).\n",
    "   3. The C++ and Numba implementations of those nodes; reference-counted data structures that manage array lifetimes.\n",
    "   4. The CPU (and someday GPU) operations that navigate and fill arrays.\n",
    "\n",
    "<img src=\"../img/awkward-1-0-layers.png\" style=\"width: 500px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spirit of NumPy—driving array-at-a-time operations from slow code with fast, precompiled kernels—is shifted down one layer: the C++ implementation is written without concern for speed, but only _O(1)_ operations are performed. The C++ is full of `std::shared_ptr` and `virtual` method calls, but _no loops over array data_ are allowed.\n",
    "\n",
    "The Numba implementation, however, needs to be fast because Numba objects will be constructed in (the user's) loops over array data.\n",
    "\n",
    "No memory allocation or deallocation is performed in layer 4. It looks a lot like C code and has a pure C interface, so that C++ and Numba can both benefit from its implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A walk through the code:** how `__getitem__(tuple)` is implemented in\n",
    "\n",
    "   * [old Awkward](https://github.com/scikit-hep/awkward-array/blob/master/awkward/array/jagged.py#L509-L779): lots of integer array tricks and `numpy.take`, valid for many special cases;\n",
    "   * [new C++](https://github.com/scikit-hep/awkward-1.0/blob/master/src/libawkward/array/ListArray.cpp#L483-L620): recursive walk through the tuple, `dynamically_casting` class types and calling C kernels;\n",
    "   * [new Numba](https://github.com/scikit-hep/awkward-1.0/blob/master/awkward1/_numba/array/listarray.py#L257-L490): recursive walk through the tuple, generating specialized code that calls C kernels;\n",
    "   * [new C kernels](https://github.com/scikit-hep/awkward-1.0/blob/master/src/cpu-kernels/getitem.cpp#L288-L509): `for` loops on raw arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Awkwardness everywhere\n",
    "\n",
    "Since the `__getitem__(tuple)` operation is actually defined in the C kernels, C++ and Numba are calling the same code when they run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.jit(nopython=True)\n",
    "def demo(array):\n",
    "    return array[:, ::-1, ::2]\n",
    "\n",
    "ak.tolist(demo(newarray.layout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That way, implementations don't diverge.\n",
    "\n",
    "Thanks to this reuse, we can also run any of these operations in C++."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open(\"test-program.cpp\", \"w\").write(\"\"\"\n",
    "\n",
    "#include \"awkward/Slice.h\"\n",
    "#include \"awkward/io/json.h\"\n",
    "#include \"awkward/array/ListOffsetArray.h\"\n",
    "\n",
    "namespace ak = awkward;\n",
    "\n",
    "int main(int, char**) {\n",
    "  std::shared_ptr<ak::Content> array = ak::FromJsonString(\n",
    "      \"[[[0.0, 1.1, 2.2], [], [3.3, 4.4]], [[5.5]], [], [[6.6, 7.7, 8.8, 9.9]]]\",\n",
    "      ak::FillableOptions(1024, 2.0));\n",
    "\n",
    "  std::vector<std::shared_ptr<ak::SliceItem>> slice({\n",
    "      std::make_shared<ak::SliceRange>(ak::Slice::none(), ak::Slice::none(), ak::Slice::none()),\n",
    "      std::make_shared<ak::SliceRange>(ak::Slice::none(), ak::Slice::none(), -1),\n",
    "      std::make_shared<ak::SliceRange>(ak::Slice::none(), ak::Slice::none(), 2)});\n",
    "\n",
    "  std::shared_ptr<ak::Content> sliced = array->getitem(ak::Slice(slice));\n",
    "  std::cout << sliced->tojson(false, 1) << std::endl;\n",
    "\n",
    "  return 0;\n",
    "}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!g++ -I../../include -L../../awkward1 test-program.cpp -lawkward-static -lawkward-cpu-kernels-static -o test-program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./test-program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 The high-level layer\n",
    "\n",
    "At present, this is the least-developed part, but that's because writing Python is easy.  `:)`\n",
    "\n",
    "The layout nodes are all mutually composable, but have been confusing to users in the old Awkward Array. Also, we want some high-level features to be persistent through slicing, and the easiest way to do this is to wrap the composable parts with their implementation details inside a non-composable \"shell\" called `ak.Array`.\n",
    "\n",
    "<img src=\"img/example-hierarchy.png\" style=\"width: 800px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "akarray = ak.Array([{\"x\": 100, \"y\": [1.1, 2.2]}, {\"x\": 200, \"y\": []}, {\"x\": 300, \"y\": [3.3]}])\n",
    "akarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "akarray.layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "akarray.layout.field(\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "akarray.layout.field(\"y\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(akarray.layout.field(\"y\").content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Behavior overloading\n",
    "\n",
    "Awkward's type system has only the basics for _representing_ data; its objects lack the _methods_ of an object-oriented language. This makes it easier to move the same data across languages (C++ and Python), but for a physicist, being able to say things like `electron.boost_to(reference_frame)` is essential.\n",
    "\n",
    "One of the most popular features of the original Awkward library was the ability to \"overlay\" behaviors onto existing arrays. In Awkward 1.0, we provide this with special-valued `parameters` attached to each layout node (and type)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointClass(ak.Record):\n",
    "    def __repr__(self):\n",
    "        return \"<Point({}, {})>\".format(self[\"x\"], self[\"y\"])\n",
    "    \n",
    "    def mag(self):\n",
    "        return abs(np.sqrt(self[\"x\"]**2 + self[\"y\"]**2))\n",
    "\n",
    "# Register the name \"Point\" to refer to PointClass.\n",
    "ak.classes[\"Point\"] = PointClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = ak.Array([{\"x\": 1, \"y\": 1.1}, {\"x\": 2, \"y\": 2.2}, {\"x\": 3, \"y\": 3.3}])\n",
    "array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By setting the `\"__class__\"` of this array as `\"Point\"`, its elements are instantiated as `PointClass`, rather than `ak.Record`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array.layout.setparameter(\"__class__\", \"Point\")\n",
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(array[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all of its methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array[1].mag()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But it's still an Awkward Array that can be sliced internally. (That's why `PointClass` has to inherit from `ak.Record` or `ak.Array`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array[\"x\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array[\"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other special parameter names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array.layout.setparameter(\"__typestr__\", \"<Point>\")\n",
    "ak.typeof(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is that this set will expand to include\n",
    "\n",
    "   * special ufunc overloads (e.g. `numpy.equal` on string-arrays compares whole strings, not inner characters),\n",
    "   * Numba-lowered instantiations, perhaps `nb.jitclass`.\n",
    "   * Numba-lowered functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incidentally, this is how strings are implemented: there is no special string-array type, just a behavior overlaid on lists of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = ak.Array([\"Daisy\", \"Daisy\", \"give\", \"me\", \"your\", \"answer\", \"do.\"])\n",
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array.layout.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array.layout.content.parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So string-arrays get all their slicing/manipulation from the standard list-array, but when you observe/operate on them, they have string-specific overloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first goal would be to make these instantiate as Numba-lowered strings in Numba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 The FillableArray builder\n",
    "\n",
    "Unlike NumPy, Awkward Arrays are immutable. (They're too complicated for `__setitem__` to make sense.)\n",
    "\n",
    "As such, we need a way to make them, so `FillableArray` provides a builder pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = ak.FillableArray()\n",
    "\n",
    "# fill commands            # equivalent JSON      # current array type\n",
    "##########################################################################################################################\n",
    "builder.beginlist()        # [                    # 0 * var * unknown\n",
    "builder.integer(1)         #   1,                 # 0 * var * int64\n",
    "builder.integer(2)         #   2,                 # 0 * var * int64\n",
    "builder.real(3)            #   3.0                # 0 * var * float64\n",
    "builder.endlist()          # ]                    # 1 * var * float64\n",
    "builder.beginlist()        # [                    # 1 * var * float64\n",
    "builder.endlist()          # ]                    # 2 * var * float64\n",
    "builder.beginlist()        # [                    # 2 * var * float64\n",
    "builder.integer(4)         #   4,                 # 2 * var * float64\n",
    "builder.null()             #   null,              # 2 * var * ?float64\n",
    "builder.integer(5)         #   5                  # 2 * var * ?float64\n",
    "builder.endlist()          # ]                    # 3 * var * ?float64\n",
    "builder.beginlist()        # [                    # 3 * var * ?float64\n",
    "builder.beginrecord()      #   {                  # 3 * var * ?union[float64, {}]\n",
    "builder.field(\"something\") #     \"something\":     # 3 * var * ?union[float64, {\"something\": unknown}]\n",
    "builder.integer(1)         #      1,              # 3 * var * ?union[float64, {\"something\": int64}]\n",
    "builder.field(\"else\")      #      \"else\":         # 3 * var * ?union[float64, {\"something\": int64, \"else\": unknown}]\n",
    "builder.beginlist()        #      [               # 3 * var * ?union[float64, {\"something\": int64, \"else\": var * unknown}]\n",
    "builder.integer(2)         #        2,            # 3 * var * ?union[float64, {\"something\": int64, \"else\": var * int64}]\n",
    "builder.integer(3)         #        3             # 3 * var * ?union[float64, {\"something\": int64, \"else\": var * int64}]\n",
    "builder.endlist()          #      ]               # 3 * var * ?union[float64, {\"something\": int64, \"else\": var * int64}]\n",
    "builder.endrecord()        #   }                  # 3 * var * ?union[float64, {\"something\": int64, \"else\": var * int64}]\n",
    "builder.endlist()          # ]                    # 4 * var * ?union[float64, {\"something\": int64, \"else\": var * int64}]\n",
    "\n",
    "ak.tolist(builder.snapshot())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The type of the data depends on the order in which `FillableArray`'s methods are called; its data depends on the values passed. You can create Awkward Arrays in the same code that would otherwise have printed out JSON. It makes the nested layout nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.snapshot().layout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can be quite free with it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepnesting(builder, depth):\n",
    "    if depth == 0:\n",
    "        builder.integer(np.random.randint(0, 10))\n",
    "    else:\n",
    "        builder.beginlist()\n",
    "        for j in range(np.random.poisson(3)):\n",
    "            deepnesting(builder, depth - 1)\n",
    "        builder.endlist()\n",
    "\n",
    "builder = ak.FillableArray()\n",
    "deepnesting(builder, 5)\n",
    "ak.tolist(builder.snapshot())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even in Numba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.jit(nopython=True)\n",
    "def deepnesting(builder, depth):\n",
    "    if depth == 0:\n",
    "        builder.integer(np.random.randint(0, 10))\n",
    "    else:\n",
    "        builder.beginlist()\n",
    "        for j in range(np.random.poisson(3)):\n",
    "            deepnesting(builder, depth - 1)\n",
    "        builder.endlist()\n",
    "\n",
    "builder = ak.layout.FillableArray()\n",
    "deepnesting(builder, 5)\n",
    "ak.tolist(builder.snapshot())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Numba, a `FillableArray` is an opaque type (entirely offloaded to C++, unlike all other implementations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.typeof(builder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The Awkward Array Numba extension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Layout node implementation example\n",
    "\n",
    "Using [ListArray](https://github.com/scikit-hep/awkward-1.0/blob/master/awkward1/_numba/array/listarray.py) as an example, each layout node class has a corresponding Numba `Type` and `Model`.\n",
    "\n",
    "`Types` carry as much information as Numba's lowering of NumPy arrays: number of dimensions and content type, but not length of each dimension.\n",
    "\n",
    "```python\n",
    "@numba.extending.typeof_impl.register(awkward1.layout.ListArray32)\n",
    "@numba.extending.typeof_impl.register(awkward1.layout.ListArrayU32)\n",
    "@numba.extending.typeof_impl.register(awkward1.layout.ListArray64)\n",
    "def typeof(val, c):\n",
    "    return ListArrayType(numba.typeof(numpy.asarray(val.starts)), numba.typeof(numpy.asarray(val.stops)), numba.typeof(val.content), numba.typeof(val.identities), util.dict2parameters(val.parameters))\n",
    "```\n",
    "\n",
    "Contents are part of the type specialization, recursively, so this information is included in the type name.\n",
    "\n",
    "```python\n",
    "class ListArrayType(content.ContentType):\n",
    "    def __init__(self, startstpe, stopstpe, contenttpe, identitiestpe, parameters):\n",
    "        assert startstpe == stopstpe\n",
    "        assert isinstance(parameters, tuple)\n",
    "        super(ListArrayType, self).__init__(name=\"ak::ListArray{0}{1}Type({2}, identities={3}, parameters={4})\".format(\"\" if startstpe.dtype.signed else \"U\", startstpe.dtype.bitwidth, contenttpe.name, identitiestpe.name, util.parameters2str(parameters)))\n",
    "        self.startstpe = startstpe\n",
    "        self.contenttpe = contenttpe\n",
    "        self.identitiestpe = identitiestpe\n",
    "        self.parameters = parameters\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the C++ implementation, I had to create my own array classes. In Numba, I use Numba's lowered NumPy arrays.\n",
    "\n",
    "```python\n",
    "@numba.extending.register_model(ListArrayType)\n",
    "class ListArrayModel(numba.datamodel.models.StructModel):\n",
    "    def __init__(self, dmm, fe_type):\n",
    "        members = [(\"starts\", fe_type.startstpe),     # always a subclass of nb.types.Array\n",
    "                   (\"stops\", fe_type.stopstpe),       # always a subclass of nb.types.Array\n",
    "                   (\"content\", fe_type.contenttpe)]   # always a subclass of content.ContentType\n",
    "        if fe_type.identitiestpe != numba.none:\n",
    "            members.append((\"identities\", fe_type.identitiestpe))\n",
    "        super(ListArrayModel, self).__init__(dmm, fe_type, members)\n",
    "```\n",
    "\n",
    "Which means that some of my lowered implementations get to use Numba's functions. I use fully qualified function names everywhere: it's verbose, but helps a lot.\n",
    "\n",
    "```python\n",
    "@numba.extending.lower_builtin(operator.getitem, ListArrayType, numba.types.Integer)\n",
    "def lower_getitem_int(context, builder, sig, args):\n",
    "    rettpe, (tpe, wheretpe) = sig.return_type, sig.args\n",
    "    val, whereval = args\n",
    "    proxyin = numba.cgutils.create_struct_proxy(tpe)(context, builder, value=val)\n",
    "\n",
    "    start = numba.targets.arrayobj.getitem_arraynd_intp(context, builder, tpe.startstpe.dtype(tpe.startstpe, wheretpe), (proxyin.starts, whereval))\n",
    "    stop = numba.targets.arrayobj.getitem_arraynd_intp(context, builder, tpe.startstpe.dtype(tpe.stopstpe, wheretpe), (proxyin.stops, whereval))\n",
    "    proxyslice = numba.cgutils.create_struct_proxy(numba.types.slice2_type)(context, builder)\n",
    "    proxyslice.start = util.cast(context, builder, tpe.startstpe.dtype, numba.intp, start)\n",
    "    proxyslice.stop = util.cast(context, builder, tpe.stopstpe.dtype, numba.intp, stop)\n",
    "    proxyslice.step = context.get_constant(numba.intp, 1)\n",
    "\n",
    "    outtpe = tpe.contenttpe.getitem_range()\n",
    "    return tpe.contenttpe.lower_getitem_range(context, builder, outtpe(tpe.contenttpe, numba.types.slice2_type), (proxyin.content, proxyslice._getvalue()))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, I couldn't find an appropriate utility function, so I've written some of my own in [util.py](https://github.com/scikit-hep/awkward-1.0/blob/master/awkward1/_numba/util.py).\n",
    "\n",
    "```python\n",
    "def cast(context, builder, fromtpe, totpe, val):\n",
    "    if isinstance(fromtpe, llvmlite.ir.types.IntType):\n",
    "        if fromtpe.width == 8:\n",
    "            fromtpe = numba.int8\n",
    "        elif fromtpe.width == 16:\n",
    "            fromtpe = numba.int16\n",
    "        elif fromtpe.width == 32:\n",
    "            fromtpe = numba.int32\n",
    "        elif fromtpe.width == 64:\n",
    "            fromtpe = numba.int64\n",
    "        else:\n",
    "            raise AssertionError(\"unrecognized bitwidth\")\n",
    "    if fromtpe.bitwidth < totpe.bitwidth:\n",
    "        return builder.sext(val, context.get_value_type(totpe))\n",
    "    elif fromtpe.bitwidth > totpe.bitwidth:\n",
    "        return builder.trunc(val, context.get_value_type(totpe))\n",
    "    else:\n",
    "        return val\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They're used, for example, when we need to call one of the C kernels.\n",
    "\n",
    "```python\n",
    "carrylength = numba.cgutils.alloca_once(builder, context.get_value_type(numba.int64))\n",
    "util.call(context, builder, determine_carrylength,\n",
    "    (carrylength,\n",
    "     util.arrayptr(context, builder, arraytpe.startstpe, proxyin.starts),\n",
    "     util.arrayptr(context, builder, arraytpe.stopstpe, proxyin.stops),\n",
    "     lenstarts,\n",
    "     context.get_constant(numba.int64, 0),\n",
    "     context.get_constant(numba.int64, 0),\n",
    "     util.cast(context, builder, numba.intp, numba.int64, proxyslicein.start),\n",
    "     util.cast(context, builder, numba.intp, numba.int64, proxyslicein.stop),\n",
    "     util.cast(context, builder, numba.intp, numba.int64, proxyslicein.step)),\n",
    "    \"in {0}, indexing error\".format(arraytpe.shortname))\n",
    "\n",
    "nextoffsets = util.newindex(arraytpe.indexname, context, builder, numba.int64, builder.add(lenstarts, context.get_constant(numba.int64, 1)))\n",
    "nextcarry = util.newindex64(context, builder, numba.int64, builder.load(carrylength))\n",
    "util.call(context, builder, fill_carry,\n",
    "    (util.arrayptr(context, builder, util.indextpe(arraytpe.indexname), nextoffsets),\n",
    "     util.arrayptr(context, builder, util.index64tpe, nextcarry),\n",
    "     util.arrayptr(context, builder, arraytpe.startstpe, proxyin.starts),\n",
    "     util.arrayptr(context, builder, arraytpe.stopstpe, proxyin.stops),\n",
    "     lenstarts,\n",
    "     context.get_constant(numba.int64, 0),\n",
    "     context.get_constant(numba.int64, 0),\n",
    "     util.cast(context, builder, numba.intp, numba.int64, proxyslicein.start),\n",
    "     util.cast(context, builder, numba.intp, numba.int64, proxyslicein.stop),\n",
    "     util.cast(context, builder, numba.intp, numba.int64, proxyslicein.step)),\n",
    "    \"in {0}, indexing error\".format(arraytpe.shortname))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We go through Numba's ctypes extension to call one fo the C kernels as an external function.\n",
    "\n",
    "_(Yes, I know this means that user code compiled with Awkward Arrays in them can't be cached.)_\n",
    "\n",
    "```python\n",
    "def call(context, builder, fcn, args, errormessage=None):\n",
    "    fcntpe = context.get_function_pointer_type(fcn.numbatpe)\n",
    "    fcnval = context.add_dynamic_addr(builder, fcn.numbatpe.get_pointer(fcn), info=fcn.name)\n",
    "    fcnptr = builder.bitcast(fcnval, fcntpe)\n",
    "\n",
    "    err = context.call_function_pointer(builder, fcnptr, args)\n",
    "\n",
    "    if fcn.restype is cpu.Error:\n",
    "        assert errormessage is not None, \"this function can return an error\"\n",
    "        proxyerr = numba.cgutils.create_struct_proxy(cpu.Error.numbatpe)(context, builder, value=err)\n",
    "        with builder.if_then(builder.icmp_signed(\"!=\", proxyerr.str, context.get_constant(numba.intp, 0)), likely=False):\n",
    "            context.call_conv.return_user_exc(builder, ValueError, (errormessage,))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `libawkward-cpu-kernels.so` is loaded in [cpu.py](https://github.com/scikit-hep/awkward-1.0/blob/master/awkward1/_numba/cpu.py). By design, these kernels have a very limited set of argument and return types.\n",
    "\n",
    "```python\n",
    "kernels = ctypes.cdll.LoadLibrary(libpath)\n",
    "\n",
    "h2ctypes = {\n",
    "    \"bool\": ctypes.c_uint8,\n",
    "    \"bool *\": ctypes.POINTER(ctypes.c_uint8),\n",
    "    \"int8_t *\": ctypes.POINTER(ctypes.c_int8),\n",
    "    \"const int8_t *\": ctypes.POINTER(ctypes.c_int8),\n",
    "    \"uint8_t *\": ctypes.POINTER(ctypes.c_uint8),\n",
    "    \"const uint8_t *\": ctypes.POINTER(ctypes.c_uint8),\n",
    "    \"int32_t\": ctypes.c_int32,\n",
    "    \"int32_t *\": ctypes.POINTER(ctypes.c_int32),\n",
    "    \"const int32_t *\": ctypes.POINTER(ctypes.c_int32),\n",
    "    \"uint32_t\": ctypes.c_uint32,\n",
    "    \"uint32_t *\": ctypes.POINTER(ctypes.c_uint32),\n",
    "    \"const uint32_t *\": ctypes.POINTER(ctypes.c_uint32),\n",
    "    \"int64_t\": ctypes.c_int64,\n",
    "    \"int64_t *\": ctypes.POINTER(ctypes.c_int64),\n",
    "    \"const int64_t *\": ctypes.POINTER(ctypes.c_int64),\n",
    "    \"Error\": Error,\n",
    "    \"ERROR\": Error,\n",
    "    \"void\": None,\n",
    "    }\n",
    "```\n",
    "\n",
    "Their signatures are read from [XML files generated by doxygen](https://github.com/scikit-hep/awkward-1.0/tree/master/awkward1/signatures) (so that I don't have to parse header files or depend on cffi)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Survey of Numba functions used\n",
    "\n",
    "Awkward Array might be the most extensive use of the Numba extension API. (Is it?) It's also my third attempt, and I've cleaned up previous attempts, having learned a lot from Numba's own codebase.\n",
    "\n",
    "Below are the decorators, classes, and functions that I've used. _Are any of these something you'd consider \"implementation details\"?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, re, types, functools, collections\n",
    "\n",
    "nbdecorators = collections.Counter()\n",
    "nbtypes = collections.Counter()\n",
    "nbfunctions = collections.Counter()\n",
    "nbclasses = collections.Counter()\n",
    "nbother = collections.Counter()\n",
    "nbbuilder = collections.Counter()\n",
    "nbcontext = collections.Counter()\n",
    "nbpyapi = collections.Counter()\n",
    "\n",
    "for filename in glob.glob(\"../../awkward1/_numba/**/*.py\", recursive=True):\n",
    "    filedata = open(filename).read()\n",
    "    for x in re.findall(r\"@(numba\\.[A-Za-z0-9_\\.]+)\", filedata):\n",
    "        nbdecorators[x] += 1\n",
    "    for x in re.findall(r\"[^_@](numba\\.[A-Za-z0-9_\\.]+)\", filedata) + re.findall(r\"^(numba\\.[A-Za-z0-9_\\.]+)\", filedata):\n",
    "        obj = eval(x, {\"numba\": nb})\n",
    "        if isinstance(obj, (nb.types.Type, nb.types.abstract._TypeMetaclass)):\n",
    "            nbtypes[x] += 1\n",
    "        elif isinstance(obj, (types.FunctionType, types.MethodType, functools.partial)):\n",
    "            nbfunctions[x] += 1\n",
    "        elif isinstance(obj, type):\n",
    "            nbclasses[x] += 1\n",
    "        elif isinstance(obj, types.ModuleType):\n",
    "            pass\n",
    "        else:\n",
    "            nbother[\"{0} ({1})\".format(x, type(obj))] += 1\n",
    "    for x in re.findall(r\"(builder\\.[A-Za-z0-9_\\.]+)\", filedata):\n",
    "        nbbuilder[x] += 1\n",
    "    for x in re.findall(r\"(context\\.[A-Za-z0-9_\\.]+)\", filedata):\n",
    "        nbcontext[x] += 1\n",
    "    for x in re.findall(r\"(c\\.pyapi\\.[A-Za-z0-9_\\.]+)\", filedata):\n",
    "        nbpyapi[x] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"decorators\")\n",
    "print(\"---------------------------------------------------------\")\n",
    "for name, freq in sorted(nbdecorators.items(), key=lambda x: -x[1]):\n",
    "    print(\"{0:5d} {1}\".format(freq, name))\n",
    "\n",
    "print(\"\\nclasses\")\n",
    "print(\"---------------------------------------------------------\")\n",
    "for name, freq in sorted(nbclasses.items(), key=lambda x: -x[1]):\n",
    "    print(\"{0:5d} {1}\".format(freq, name))\n",
    "\n",
    "print(\"\\nfunctions\")\n",
    "print(\"---------------------------------------------------------\")\n",
    "for name, freq in sorted(nbfunctions.items(), key=lambda x: -x[1]):\n",
    "    print(\"{0:5d} {1}\".format(freq, name))\n",
    "\n",
    "print(\"\\nbuilder.*\")\n",
    "print(\"---------------------------------------------------------\")\n",
    "for name, freq in sorted(nbbuilder.items(), key=lambda x: -x[1]):\n",
    "    print(\"{0:5d} {1}\".format(freq, name))\n",
    "\n",
    "print(\"\\ncontext.*\")\n",
    "print(\"---------------------------------------------------------\")\n",
    "for name, freq in sorted(nbcontext.items(), key=lambda x: -x[1]):\n",
    "    print(\"{0:5d} {1}\".format(freq, name))\n",
    "\n",
    "print(\"\\npyapi.*\")\n",
    "print(\"---------------------------------------------------------\")\n",
    "for name, freq in sorted(nbpyapi.items(), key=lambda x: -x[1]):\n",
    "    print(\"{0:5d} {1}\".format(freq, name))\n",
    "\n",
    "print(\"\\ntypes\")\n",
    "print(\"---------------------------------------------------------\")\n",
    "for name, freq in sorted(nbtypes.items(), key=lambda x: -x[1]):\n",
    "    print(\"{0:5d} {1}\".format(freq, name))\n",
    "\n",
    "print(\"\\nother\")\n",
    "print(\"---------------------------------------------------------\")\n",
    "for name, freq in sorted(nbother.items(), key=lambda x: -x[1]):\n",
    "    print(\"{0:5d} {1}\".format(freq, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 My questions for you\n",
    "\n",
    "   1. How, in general, should one debug `context.nrt` reference counts?\n",
    "      * Too many `context.nrt.increfs` causes a memory leak while a JIT'ed function is running, but do references persist after it exits? Is a Numba function like a process?\n",
    "      * Are `context.nrt` reference counts tied to Python reference counts?\n",
    "   4. The extension mechanism doesn't seem to work in CUDA. Am I missing something or is CUDA off the table?\n",
    "   5. From performance measurements, I think `StructModels` are pass-by-value. Eventually, I may need to replace them with pass-by-reference. Which `Model` should I use for that and what issues should I consider?\n",
    "   6. Is anyone interested in collaborating on the Awkward-Numba interface? Would you have reason to do so \"if only...\"?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
